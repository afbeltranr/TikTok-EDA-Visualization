{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration Notebook\n",
    "\n",
    "## Introduction\n",
    "This notebook demonstrates the process of securely accessing a dataset stored in Google Sheets using the Google Cloud Platform (GCP) Service Account. This initial section outlines key milestones achieved to set up a secure and efficient workflow for this project.\n",
    "\n",
    "## Milestones Achieved\n",
    "1. **GCP Service Account Configuration**:\n",
    "   - Successfully created and configured a GCP Service Account to access the Google Sheets API.\n",
    "   - Shared the dataset file in Google Sheets with the service account email to grant edit permissions.\n",
    "\n",
    "2. **Secure Credential Management**:\n",
    "   - Implemented the use of environment variables to securely store and access the path to the service account JSON file.\n",
    "   - Ensured the JSON credentials file is not committed to the repository by:\n",
    "     - Adding the `secrets/` directory and `.env` file to the `.gitignore`.\n",
    "     - Setting up environment variables dynamically during virtual environment activation.\n",
    "\n",
    "3. **Virtual Environment Setup**:\n",
    "   - Created and utilized a Python virtual environment for package management.\n",
    "   - Ensured the virtual environment includes all required dependencies, isolating the project environment from the global system.\n",
    "\n",
    "4. **Data Access**:\n",
    "   - Successfully retrieved the dataset from Google Sheets into a Pandas DataFrame for analysis, confirming seamless integration between GCP and the project.\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below does the following:\n",
    "- Imports the necessary libraries: \n",
    "\n",
    "    -`os` to extract environment variables.\n",
    "\n",
    "    -`Credentials` class from the `google.oauth2.service_account` module for authenticating the service account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "# Get the path from the environment variable\n",
    "json_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'GOOGLE_APPLICATION_CREDENTIALS' environment variable is set to the path of the service account JSON file. This variable is used by the Google Cloud client libraries to locate the service account credentials.\n",
    "\n",
    "Now, as the next step we can import the following libraries:\n",
    "\n",
    "- `gspread` to interact with Google Sheets.\n",
    "- `pandas` to work with the dataset.\n",
    "\n",
    "\n",
    "Also, some classes, such as `Credentials` from the `google.oauth2.service_account` module, and `Request` from the `google.auth.transport.requests` module are imported to authenticate the service account and make requests to the Google Sheets API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.service_account import Credentials\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will get the environment variable that holds the path to the gcp service account .json file, which is not commited to this repository (included in the .gitignore file). If you wish to do the same I recommend to edit the activate script of your virtual environment to set the environment variable every time you activate it. \n",
    "\n",
    "the `getenv` function from the `os` module is used to get the value of the 'GOOGLE_APPLICATION_CREDENTIALS' environment variable and saves it into the `json_path` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "if not json_path:\n",
    "    raise FileNotFoundError(\"Environment variable GOOGLE_APPLICATION_CREDENTIALS is not set or file path is invalid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, the `json_path` variable is used to authenticate the service account and access the Google Sheets API. The `Credentials.from_service_account_file` method is used to create credentials from the service account JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Authenticate using the service account JSON file\n",
    "scopes = [\"https://www.googleapis.com/auth/spreadsheets.readonly\"]\n",
    "credentials = Credentials.from_service_account_file(json_path, scopes=scopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the `gspread.authorize` method is used to authenticate the service account and access the Google Sheets API. \n",
    "\n",
    "this information is saved in the `client` variable, which is used to access the Google Sheets API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Authorize the gspread client\n",
    "client = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we can pass the spreadsheet url to the `open_by_url` method of the `client` object to access the Google Sheets file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Open the Google Sheet by URL\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1f7jIcEzhLiO2EhVZro8oUdNgm2AGaC5po8QNiuQggG4/edit?usp=sharing\"\n",
    "spreadsheet = client.open_by_url(spreadsheet_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select the first worksheet of the Google Sheets file using the `get_worksheet` method of the `spreadsheet` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Select the worksheet (e.g., first worksheet)\n",
    "worksheet = spreadsheet.get_worksheet(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the worksheet is selected, we can fetch all the records from the worksheets as a list of dictionaries. This is done using the `get_all_records` method of the `worksheet` object.\n",
    "\n",
    "Then, we can convert the list of dictionaries to a Pandas DataFrame using the `pd.DataFrame` constructor. This will allow us to perform data analysis and visualization on the dataset.\n",
    "\n",
    "Finally, we can display the first few rows of the dataset using the `head` method of the Pandas DataFrame.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   # claim_status    video_id  video_duration_sec  \\\n",
      "0  1        claim  7017666017                  59   \n",
      "1  2        claim  4014381136                  32   \n",
      "2  3        claim  9859838091                  31   \n",
      "3  4        claim  1866847991                  25   \n",
      "4  5        claim  7105231098                  19   \n",
      "\n",
      "                            video_transcription_text verified_status  \\\n",
      "0  someone shared with me that drone deliveries a...    not verified   \n",
      "1  someone shared with me that there are more mic...    not verified   \n",
      "2  someone shared with me that american industria...    not verified   \n",
      "3  someone shared with me that the metro of st. p...    not verified   \n",
      "4  someone shared with me that the number of busi...    not verified   \n",
      "\n",
      "  author_ban_status video_view_count video_like_count video_share_count  \\\n",
      "0      under review           343296            19425               241   \n",
      "1            active           140877            77355             19034   \n",
      "2            active           902185            97690              2858   \n",
      "3            active           437506           239954             34812   \n",
      "4            active            56167            34987              4110   \n",
      "\n",
      "  video_download_count video_comment_count  \n",
      "0                    1                   0  \n",
      "1                 1161                 684  \n",
      "2                  833                 329  \n",
      "3                 1234                 584  \n",
      "4                  547                 152  \n"
     ]
    }
   ],
   "source": [
    "# Step 6: Load data into a pandas DataFrame\n",
    "data = worksheet.get_all_records()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have access to the data, we can proceed to do some Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "The particular interest of this project is explore information related to what disntinguishes claim videos from opinion videos.\n",
    "\n",
    "Now we will assess the data. we already checked the dataset contents using the .head() method, now we will check the data types of the columns using the .info() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19382 entries, 0 to 19381\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   #                         19382 non-null  int64 \n",
      " 1   claim_status              19382 non-null  object\n",
      " 2   video_id                  19382 non-null  int64 \n",
      " 3   video_duration_sec        19382 non-null  int64 \n",
      " 4   video_transcription_text  19382 non-null  object\n",
      " 5   verified_status           19382 non-null  object\n",
      " 6   author_ban_status         19382 non-null  object\n",
      " 7   video_view_count          19382 non-null  object\n",
      " 8   video_like_count          19382 non-null  object\n",
      " 9   video_share_count         19382 non-null  object\n",
      " 10  video_download_count      19382 non-null  object\n",
      " 11  video_comment_count       19382 non-null  object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics can also be used in this stage of EDA to summarize the central tendency, dispersion, and shape of the datasetâ€™s distribution. This can be done using the .describe() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19382.000000</td>\n",
       "      <td>1.938200e+04</td>\n",
       "      <td>19382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9691.500000</td>\n",
       "      <td>5.627454e+09</td>\n",
       "      <td>32.421732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5595.245794</td>\n",
       "      <td>2.536440e+09</td>\n",
       "      <td>16.229967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.234959e+09</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4846.250000</td>\n",
       "      <td>3.430417e+09</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9691.500000</td>\n",
       "      <td>5.618664e+09</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14536.750000</td>\n",
       "      <td>7.843960e+09</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19382.000000</td>\n",
       "      <td>9.999873e+09</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #      video_id  video_duration_sec\n",
       "count  19382.000000  1.938200e+04        19382.000000\n",
       "mean    9691.500000  5.627454e+09           32.421732\n",
       "std     5595.245794  2.536440e+09           16.229967\n",
       "min        1.000000  1.234959e+09            5.000000\n",
       "25%     4846.250000  3.430417e+09           18.000000\n",
       "50%     9691.500000  5.618664e+09           32.000000\n",
       "75%    14536.750000  7.843960e+09           47.000000\n",
       "max    19382.000000  9.999873e+09           60.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to assess the distributions of the variables and identify outliers, we can create box plots for the numerical columns and histograms for the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
